{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping irrelevant columns \n",
      "Rows: 30\n",
      "Columns: 956\n",
      "\n",
      "After dropping irrelevant columns \n",
      "Rows: 30\n",
      "Columns: 608\n",
      "\n",
      "After dropping incomplete surveys \n",
      "Rows: 30\n",
      "Columns: 606\n",
      "\n",
      "Cleaned dataset saved to: ../../../data/human_eval/human_eval_cleaned.csv\n",
      "Emails with 'gsovp' missing or 'A1' saved to: ../../../data/sensitive/human_mail_1.csv\n",
      "Emails with 'gsovp' == 'A2' saved to: ../../../data/sensitive/human_mail_a2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_survey_data(input_csv, output_cleaned_csv, output_emails_csv_a1, output_emails_csv_a2, output_raw_csv):\n",
    "    \"\"\"\n",
    "    Process a single CSV file to separate emails and clean data based on 'gsovp' column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_csv : str\n",
    "        Path to the input CSV file.\n",
    "    output_cleaned_csv : str\n",
    "        File path to save the cleaned CSV (excluding the email column).\n",
    "    output_emails_csv_a1 : str\n",
    "        File path to save emails where 'gsovp' == 'A1'.\n",
    "    output_emails_csv_a2 : str\n",
    "        File path to save emails where 'gsovp' == 'A2'.\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(input_csv)\n",
    "    df_raw = df_raw.drop(columns=['email'], errors='ignore')\n",
    "    df_raw.to_csv(output_raw_csv, index=False)\n",
    "    # Read the input CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Filter only completed surveys\n",
    "    df = df[df['lastpage'] == 70]\n",
    "\n",
    "    emails_a1 = pd.DataFrame()\n",
    "    emails_a2 = pd.DataFrame()\n",
    "\n",
    "    if 'email' in df.columns:\n",
    "        email_df = df[['email']].copy()\n",
    "\n",
    "        if 'gsovp' in df.columns:\n",
    "            # Separate emails based on 'gsovp' values\n",
    "            emails_a1 = email_df[df['gsovp'] == 'A1']\n",
    "            emails_a2 = email_df[df['gsovp'] == 'A2']\n",
    "\n",
    "        # Drop the email column from the main DataFrame\n",
    "        df = df.drop(columns=['email'])\n",
    "\n",
    "    # Further cleaning of df\n",
    "    # print rows and columns after dropping irrelevant columns\n",
    "    print(\"Before dropping irrelevant columns \")\n",
    "    print(f'Rows: {df.shape[0]}')\n",
    "    print(f'Columns: {df.shape[1]}\\n')\n",
    "    # Drop irrelevant columns directly to ensure anonymity and clean structure\n",
    "    columns_to_drop = ['email', 'submitdate', 'seed', 'startlanguage']  # Columns we don't need\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
    "\n",
    "    # Drop all columns containing 'Time' in the name\n",
    "    df = df.drop(columns=[col for col in df.columns if 'Time' in col], errors='ignore')\n",
    "\n",
    "    # print rows and columns after dropping irrelevant columns\n",
    "    print(\"After dropping irrelevant columns \")\n",
    "    print(f'Rows: {df.shape[0]}')\n",
    "    print(f'Columns: {df.shape[1]}\\n')\n",
    "\n",
    "    # Drop lastpage column\n",
    "    df = df.drop(columns=['lastpage'])\n",
    "    # Drop 'gsovp' column\n",
    "    df = df.drop(columns=['gsovp'])\n",
    "\n",
    "    # Print rows and column after dropping incomplete surveys\n",
    "    print(\"After dropping incomplete surveys \")\n",
    "    print(f'Rows: {df.shape[0]}')\n",
    "    print(f'Columns: {df.shape[1]}\\n')\n",
    "\n",
    "    # Map education status to roles\n",
    "    role_mapping = {\n",
    "        'A2': 'prospective',\n",
    "        'A3': 'prospective',\n",
    "        'A4': 'enrolled',\n",
    "        'A5': 'international',\n",
    "        'A1': 'other',\n",
    "        'A6': 'other',\n",
    "        'A7': 'other',\n",
    "        'A8': 'other'\n",
    "    }\n",
    "    df['role'] = df['educationstatus'].map(role_mapping)\n",
    "\n",
    "\n",
    "    # Save the cleaned data and email groups to separate files\n",
    "    df.to_csv(output_cleaned_csv, index=False)\n",
    "    emails_a1.to_csv(output_emails_csv_a1, index=False)\n",
    "    emails_a2.to_csv(output_emails_csv_a2, index=False)\n",
    "\n",
    "    print(f\"Cleaned dataset saved to: {output_cleaned_csv}\")\n",
    "    print(f\"Emails with 'gsovp' missing or 'A1' saved to: {output_emails_csv_a1}\")\n",
    "    print(f\"Emails with 'gsovp' == 'A2' saved to: {output_emails_csv_a2}\")\n",
    "\n",
    "process_survey_data(\n",
    "    input_csv=\"../../../data/sensitive/eval_raw_18_01_2025.csv\",\n",
    "    output_cleaned_csv=\"../../../data/human_eval/human_eval_cleaned.csv\",\n",
    "    output_emails_csv_a1=\"../../../data/sensitive/human_mail_1.csv\",\n",
    "    output_emails_csv_a2=\"../../../data/sensitive/human_mail_a2.csv\",\n",
    "    output_raw_csv=\"../../../data/human_eval/human_eval_raw.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>randomgroup</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender[other]</th>\n",
       "      <th>educationlevel</th>\n",
       "      <th>educationstatus</th>\n",
       "      <th>program</th>\n",
       "      <th>familiar</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>question_number</th>\n",
       "      <th>qid</th>\n",
       "      <th>langq</th>\n",
       "      <th>comment</th>\n",
       "      <th>hallucination</th>\n",
       "      <th>answer_acc</th>\n",
       "      <th>user_sat</th>\n",
       "      <th>coherence</th>\n",
       "      <th>context_qual</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>123.0</td>\n",
       "      <td>de</td>\n",
       "      <td>Bei dieser Antwort frage ich mich wirklich war...</td>\n",
       "      <td>A3</td>\n",
       "      <td>A1</td>\n",
       "      <td>A2</td>\n",
       "      <td>A4</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>153.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3</td>\n",
       "      <td>A3</td>\n",
       "      <td>A3</td>\n",
       "      <td>A2</td>\n",
       "      <td>A4</td>\n",
       "      <td>A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>328.0</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5</td>\n",
       "      <td>A3</td>\n",
       "      <td>A4</td>\n",
       "      <td>A1</td>\n",
       "      <td>A3</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>123.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3</td>\n",
       "      <td>A2</td>\n",
       "      <td>A3</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>298.0</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A4</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>A4</td>\n",
       "      <td>A4</td>\n",
       "      <td>A4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  randomgroup age gender  gender[other] educationlevel educationstatus  \\\n",
       "0  26            7  A2     A2            NaN             A5              A4   \n",
       "1  26            7  A2     A2            NaN             A5              A4   \n",
       "2  26            7  A2     A2            NaN             A5              A4   \n",
       "3  26            7  A2     A2            NaN             A5              A4   \n",
       "4  26            7  A2     A2            NaN             A5              A4   \n",
       "\n",
       "             program familiar  description  ...  question_number    qid  \\\n",
       "0  Cognitive Science       A3          NaN  ...               43  123.0   \n",
       "1  Cognitive Science       A3          NaN  ...               44  153.0   \n",
       "2  Cognitive Science       A3          NaN  ...               45  328.0   \n",
       "3  Cognitive Science       A3          NaN  ...               46  123.0   \n",
       "4  Cognitive Science       A3          NaN  ...               47  298.0   \n",
       "\n",
       "   langq                                            comment hallucination  \\\n",
       "0     de  Bei dieser Antwort frage ich mich wirklich war...            A3   \n",
       "1     en                                                NaN            A3   \n",
       "2     de                                                NaN            A5   \n",
       "3     en                                                NaN            A3   \n",
       "4     de                                                NaN            A4   \n",
       "\n",
       "  answer_acc user_sat coherence context_qual overall  \n",
       "0         A1       A2        A4           A2      A2  \n",
       "1         A3       A3        A2           A4      A3  \n",
       "2         A3       A4        A1           A3      A2  \n",
       "3         A2       A3        A2           A2      A2  \n",
       "4         A5       A4        A4           A4      A4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform_survey_wide_to_long(input_csv: str, output_csv: str, survey_csv: str) -> None:\n",
    "    \"\"\"\n",
    "    Transforms the wide-format survey data into a long format such that each row\n",
    "    corresponds to one question-answer pair from one participant.\n",
    "\n",
    "    :param input_csv:  Path to the original wide CSV file.\n",
    "    :param output_csv: Path to the output CSV file in long format.\n",
    "    :param survey_csv: Path to the survey CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the wide-format CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Define the mapping from randomgroup -> the actual questions answered\n",
    "    QUESTION_GROUPS = {\n",
    "        1: range(1, 8),    # ans1 ... ans7\n",
    "        2: range(8, 15),   # ans8 ... ans14\n",
    "        3: range(15, 22),  # ans15 ... ans21\n",
    "        4: range(22, 29),  # ans22 ... ans28\n",
    "        5: range(29, 36),  # ans29 ... ans35\n",
    "        6: range(36, 43),  # ans36 ... ans42\n",
    "        7: range(43, 49),  # ans43 ... ans48\n",
    "        8: range(49, 55),  # ans49 ... ans54\n",
    "        9: range(55, 61),  # ans55 ... ans60\n",
    "        10: range(61, 67), # ans61 ... ans66\n",
    "    }\n",
    "\n",
    "    # Columns at participant level you want to carry into the long dataframe.\n",
    "    # Adjust this list to your needs (e.g., add or remove columns as needed).\n",
    "    participant_cols = [\n",
    "        'id', 'langprof', 'randomgroup', 'age', 'gender', 'gender[other]',\n",
    "        'educationlevel', 'educationstatus', 'program', 'familiar', 'description',\n",
    "        'interviewtime', 'role'\n",
    "    ]\n",
    "\n",
    "    # Prepare a list to collect all the long-format rows\n",
    "    long_rows = []\n",
    "\n",
    "    # Iterate over each participant (row in the wide dataframe)\n",
    "    for _, row in df.iterrows():\n",
    "        # Identify which questions this participant answered\n",
    "        rg = row['randomgroup']\n",
    "        question_list = QUESTION_GROUPS.get(rg, [])\n",
    "\n",
    "        # For each question in that randomgroup\n",
    "        for q_num in question_list:\n",
    "            # Build a dict that will become one row in the long dataframe\n",
    "            new_row = {}\n",
    "\n",
    "            # 1) Bring over all participant-level data\n",
    "            for col in participant_cols:\n",
    "                # Some participants might have missing columns for 'gender[other]' etc.\n",
    "                # so we safely do a .get() if you want to be defensive.\n",
    "                # Here, we assume the column exists in df.\n",
    "                new_row[col] = row[col]\n",
    "\n",
    "            # 2) Question-specific columns: qidXX, langqXX, commentXX\n",
    "            qid_col     = f'qid{q_num}'\n",
    "            langq_col   = f'langq{q_num}'\n",
    "            comment_col = f'comment{q_num}'\n",
    "\n",
    "            # It's good practice to check if the columns exist, in case of partial data\n",
    "            new_row['question_number'] = q_num\n",
    "            new_row['qid']     = row[qid_col]     if qid_col     in df.columns else None\n",
    "            new_row['langq']   = row[langq_col]   if langq_col   in df.columns else None\n",
    "            new_row['comment'] = row[comment_col] if comment_col in df.columns else None\n",
    "\n",
    "            # 3) The 6 Likert ratings: ansXX[SQ001] ... ansXX[SQ006]\n",
    "            #    We'll store them in columns named dim1 ... dim6 (or pick any naming scheme)\n",
    "            for sq_idx in range(1, 7):\n",
    "                sq_col = f'ans{q_num}[SQ00{sq_idx}]'\n",
    "                if sq_col in df.columns:\n",
    "                    new_row[f'dim{sq_idx}'] = row[sq_col]\n",
    "                else:\n",
    "                    new_row[f'dim{sq_idx}'] = None\n",
    "\n",
    "            # Append the newly created dictionary to our list of rows\n",
    "            long_rows.append(new_row)\n",
    "\n",
    "    # Turn that list of dictionaries into a DataFrame\n",
    "    long_df = pd.DataFrame(long_rows)\n",
    "\n",
    "    # # for whatever reason qid and langq are not in the original data for some randomgroups\n",
    "    # fill them in from the df_for_survey.csv\n",
    "    df_survey = pd.read_csv(survey_csv)\n",
    "    # Override data_eval columns 'qid' and 'langq' with df_survey columns 'question_id' and 'df_language' \n",
    "    # for rows where df_survey 'index +1' is equal to data_eval 'question_number'\n",
    "    for idx, row in df_survey.iterrows():\n",
    "        question_number = idx + 1\n",
    "        long_df.loc[long_df['question_number'] == question_number, 'qid'] = row['question_id']\n",
    "        long_df.loc[long_df['question_number'] == question_number, 'langq'] = row['df_language']\n",
    "\n",
    "    long_df.drop(columns=['langprof'], inplace=True)\n",
    "\n",
    "    # Rename column\n",
    "    long_df.rename(columns={'dim1': 'hallucination'}, inplace=True)\n",
    "    long_df.rename(columns={'dim2': 'answer_acc'}, inplace=True)\n",
    "    long_df.rename(columns={'dim3': 'user_sat'}, inplace=True)\n",
    "    long_df.rename(columns={'dim4': 'coherence'}, inplace=True)\n",
    "    long_df.rename(columns={'dim5': 'context_qual'}, inplace=True)\n",
    "    long_df.rename(columns={'dim6': 'overall'}, inplace=True)\n",
    "\n",
    "    # Finally, write out the long-format data to CSV\n",
    "    long_df.to_csv(output_csv, index=False, quoting=1)\n",
    "    return long_df\n",
    "\n",
    "# -------------- USAGE EXAMPLE -------------- #\n",
    "\n",
    "data = transform_survey_wide_to_long(\n",
    "    input_csv=\"../../../data/human_eval/human_eval_cleaned.csv\", \n",
    "    output_csv=\"../../../data/human_eval/human_eval_long.csv\",\n",
    "    survey_csv=\"../../../data/human_eval/df_for_survey.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>qid</th>\n",
       "      <th>langq</th>\n",
       "      <th>avg_hallucination</th>\n",
       "      <th>avg_answer_acc</th>\n",
       "      <th>avg_user_sat</th>\n",
       "      <th>avg_coherence</th>\n",
       "      <th>avg_context_qual</th>\n",
       "      <th>avg_overall</th>\n",
       "      <th>overall_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>238.0</td>\n",
       "      <td>de</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>315.0</td>\n",
       "      <td>en</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>111.0</td>\n",
       "      <td>de</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>336.0</td>\n",
       "      <td>en</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>de</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_number    qid langq  avg_hallucination  avg_answer_acc  \\\n",
       "0                1  238.0    de           4.666667        4.666667   \n",
       "1                2  315.0    en           4.333333        4.333333   \n",
       "2                3  111.0    de           4.333333        4.333333   \n",
       "3                4  336.0    en           4.333333        4.333333   \n",
       "4                5   32.0    de           5.000000        5.000000   \n",
       "\n",
       "   avg_user_sat  avg_coherence  avg_context_qual  avg_overall  overall_mean  \n",
       "0      4.666667       4.666667          4.666667     4.666667      4.666667  \n",
       "1      3.666667       4.333333          4.333333     4.000000      4.200000  \n",
       "2      4.333333       4.666667          4.333333     4.333333      4.400000  \n",
       "3      4.333333       4.666667          3.666667     4.333333      4.266667  \n",
       "4      4.666667       5.000000          4.333333     5.000000      4.800000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the long-format dataset\n",
    "data = pd.read_csv(\"../../../data/human_eval/human_eval_long.csv\", encoding='utf-8')\n",
    "\n",
    "# Convert categorical ratings to numeric for computation\n",
    "rating_map = {'A1': 1, 'A2': 2, 'A3': 3, 'A4': 4, 'A5': 5}\n",
    "for col in ['hallucination', 'answer_acc', 'user_sat', 'coherence', 'context_qual', 'overall']:\n",
    "    data[col] = data[col].map(rating_map)\n",
    "\n",
    "# Group by question and calculate the mean for each dimension\n",
    "average_scores = data.groupby(['question_number', 'qid', 'langq']).agg({\n",
    "    'hallucination': 'mean',\n",
    "    'answer_acc': 'mean',\n",
    "    'user_sat': 'mean',\n",
    "    'coherence': 'mean',\n",
    "    'context_qual': 'mean',\n",
    "    'overall': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Save the result to a new DataFrame\n",
    "average_scores_df = average_scores.rename(columns={\n",
    "    'hallucination': 'avg_hallucination',\n",
    "    'answer_acc': 'avg_answer_acc',\n",
    "    'user_sat': 'avg_user_sat',\n",
    "    'coherence': 'avg_coherence',\n",
    "    'context_qual': 'avg_context_qual',\n",
    "    'overall': 'avg_overall'\n",
    "})\n",
    "\n",
    "# Add the 'overall_mean' column as the average of the specified columns\n",
    "average_scores_df['overall_mean'] = average_scores_df[[\n",
    "    'avg_hallucination', \n",
    "    'avg_answer_acc', \n",
    "    'avg_user_sat', \n",
    "    'avg_coherence', \n",
    "    'avg_context_qual'\n",
    "]].mean(axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "average_scores_df.to_csv(\"../../../data/human_eval_avg.csv\", index=False, quoting=1)\n",
    "\n",
    "# Show the first few rows of the updated DataFrame\n",
    "average_scores_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survey_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
